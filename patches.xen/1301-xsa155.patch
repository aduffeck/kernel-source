From http://xenbits.xen.org/hg/linux-2.6.18-xen.hg/rev/52a7179e39e7
From: xen-devel@lists.xenproject.org
Patch-mainline: Never, SUSE-Xen specific
Subject: backends: guarantee one time reads of shared ring contents
References: bsc#957988 CVE-2015-8550 XSA-155

Address double fetch vulnerabilities, occurring when a variable is
fetched twice from shared memory but a security check is only
performed on the first fetched value.

This is part of CVE-2015-8550 / XSA-155.

Signed-off-by: Jan Beulich <jbeulich@suse.com>

--- a/drivers/xen/blkback/blkback.c
+++ b/drivers/xen/blkback/blkback.c
@@ -363,6 +363,9 @@ static int _do_block_io_op(blkif_t *blki
 
 		++rc;
 
+		/* Apply all sanity checks to /private copy/ of request. */
+		barrier();
+
 		switch (req.operation) {
 		case BLKIF_OP_READ:
 		case BLKIF_OP_WRITE:
@@ -375,10 +378,6 @@ static int _do_block_io_op(blkif_t *blki
 
 			/* before make_response() */
 			blk_rings->common.req_cons = rc;
-
-			/* Apply all sanity checks to /private copy/ of request. */
-			barrier();
-
 			dispatch_rw_block_io(blkif, &req, pending_req);
 			break;
 		default:
@@ -386,7 +385,6 @@ static int _do_block_io_op(blkif_t *blki
 			 * avoid excessive CPU consumption by a bad guest. */
 			msleep(1);
 			blk_rings->common.req_cons = rc;
-			barrier();
 			DPRINTK("error: unknown block io operation [%d]\n",
 				req.operation);
 			make_response(blkif, req.id, req.operation,
--- a/drivers/xen/netback/netback.c
+++ b/drivers/xen/netback/netback.c
@@ -1056,6 +1056,7 @@ static int netbk_count_requests(netif_t
 
 		memcpy(txp, RING_GET_REQUEST(&netif->tx, cons + frags),
 		       sizeof(*txp));
+		barrier();
 
 		/*
 		 * If the guest submitted a frame >= 64 KiB then first->size
@@ -1236,6 +1237,7 @@ int netbk_get_extras(netif_t *netif, str
 
 		memcpy(&extra, RING_GET_REQUEST(&netif->tx, cons),
 		       sizeof(extra));
+		barrier();
 		if (unlikely(!extra.type ||
 			     extra.type >= XEN_NETIF_EXTRA_TYPE_MAX)) {
 			netif->tx.req_cons = ++cons;
@@ -1334,6 +1336,7 @@ static void net_tx_action(unsigned long
 		i = netif->tx.req_cons;
 		rmb(); /* Ensure that we see the request before we copy it. */
 		memcpy(&txreq, RING_GET_REQUEST(&netif->tx, i), sizeof(txreq));
+		barrier();
 
 		/* Credit-based scheduling. */
 		if (txreq.size > netif->remaining_credit) {
--- a/drivers/xen/scsiback/scsiback.c
+++ b/drivers/xen/scsiback/scsiback.c
@@ -515,11 +515,13 @@ static int prepare_pending_reqs(struct v
 
 	pending_req->info       = info;
 
-	pending_req->v_chn = vir.chn = ring_req->channel;
-	pending_req->v_tgt = vir.tgt = ring_req->id;
+	vir.chn = ring_req->channel;
+	vir.tgt = ring_req->id;
 	vir.lun = ring_req->lun;
-
 	rmb();
+	pending_req->v_chn = vir.chn;
+	pending_req->v_tgt = vir.tgt;
+
 	sdev = scsiback_do_translation(info, &vir);
 	if (!sdev) {
 		pending_req->sdev = NULL;
--- a/drivers/xen/tpmback/tpmback.c
+++ b/drivers/xen/tpmback/tpmback.c
@@ -245,17 +245,16 @@ int _packet_write(struct packet *pak,
 		unsigned int tocopy;
 		struct gnttab_map_grant_ref map_op;
 		struct gnttab_unmap_grant_ref unmap_op;
-		tpmif_tx_request_t *tx;
+		tpmif_tx_request_t tx = tpmif->tx->ring[i].req;
 
-		tx = &tpmif->tx->ring[i].req;
-
-		if (0 == tx->addr) {
+		rmb();
+		if (0 == tx.addr) {
 			DPRINTK("ERROR: Buffer for outgoing packet NULL?! i=%d\n", i);
 			return 0;
 		}
 
 		gnttab_set_map_op(&map_op, idx_to_kaddr(tpmif, i),
-				  GNTMAP_host_map, tx->ref, tpmif->domid);
+				  GNTMAP_host_map, tx.ref, tpmif->domid);
 
 		gnttab_check_GNTST_eagain_do_while(GNTTABOP_map_grant_ref, &map_op);
 
@@ -269,12 +268,12 @@ int _packet_write(struct packet *pak,
 		tocopy = min_t(size_t, size - offset, PAGE_SIZE);
 
 		if (copy_from_buffer((void *)(idx_to_kaddr(tpmif, i) |
-					      (tx->addr & ~PAGE_MASK)),
+					      (tx.addr & ~PAGE_MASK)),
 				     &data[offset], tocopy, isuserbuffer)) {
 			tpmif_put(tpmif);
 			return -EFAULT;
 		}
-		tx->size = tocopy;
+		tpmif->tx->ring[i].req.size = tocopy;
 
 		gnttab_set_unmap_op(&unmap_op, idx_to_kaddr(tpmif, i),
 				    GNTMAP_host_map, handle);
@@ -373,9 +372,6 @@ static int packet_read_shmem(struct pack
 	u32 to_copy;
 	grant_handle_t handle;
 
-	tpmif_tx_request_t *tx;
-
-	tx = &tpmif->tx->ring[0].req;
 	/*
 	 * Start copying data at the page with index 'index'
 	 * and within that page at offset 'offset'.
@@ -386,11 +382,11 @@ static int packet_read_shmem(struct pack
 		void *src;
 		struct gnttab_map_grant_ref map_op;
 		struct gnttab_unmap_grant_ref unmap_op;
+		tpmif_tx_request_t tx = tpmif->tx->ring[i].req;
 
-		tx = &tpmif->tx->ring[i].req;
-
+		rmb();
 		gnttab_set_map_op(&map_op, idx_to_kaddr(tpmif, i),
-				  GNTMAP_host_map, tx->ref, tpmif->domid);
+				  GNTMAP_host_map, tx.ref, tpmif->domid);
 
 		gnttab_check_GNTST_eagain_do_while(GNTTABOP_map_grant_ref, &map_op);
 
@@ -401,19 +397,19 @@ static int packet_read_shmem(struct pack
 
 		handle = map_op.handle;
 
-		if (to_copy > tx->size) {
+		if (to_copy > tx.size) {
 			/*
 			 * User requests more than what's available
 			 */
-			to_copy = min_t(u32, tx->size, to_copy);
+			to_copy = min_t(u32, tx.size, to_copy);
 		}
 
 		DPRINTK("Copying from mapped memory at %08lx\n",
 			(unsigned long)(idx_to_kaddr(tpmif, i) |
-					(tx->addr & ~PAGE_MASK)));
+					(tx.addr & ~PAGE_MASK)));
 
 		src = (void *)(idx_to_kaddr(tpmif, i) |
-			       ((tx->addr & ~PAGE_MASK) + pg_offset));
+			       ((tx.addr & ~PAGE_MASK) + pg_offset));
 		if (copy_to_buffer(&buffer[offset],
 				   src, to_copy, isuserbuffer)) {
 			return -EFAULT;
@@ -874,21 +870,23 @@ static void tpm_tx_action(unsigned long
 {
 	struct list_head *ent;
 	tpmif_t *tpmif;
-	tpmif_tx_request_t *tx;
 
 	DPRINTK("%s: Getting data from front-end(s)!\n", __FUNCTION__);
 
 	while (!list_empty(&tpm_schedule_list)) {
+		tpmif_tx_request_t tx;
+
 		/* Get a tpmif from the list with work to do. */
 		ent = tpm_schedule_list.next;
 		tpmif = list_entry(ent, tpmif_t, list);
 		tpmif_get(tpmif);
 		remove_from_tpm_schedule_list(tpmif);
 
-		tx = &tpmif->tx->ring[0].req;
+		tx = tpmif->tx->ring[0].req;
+		rmb();
 
 		/* pass it up */
-		vtpm_receive(tpmif, tx->size);
+		vtpm_receive(tpmif, tx.size);
 
 		tpmif_put(tpmif);
 	}
